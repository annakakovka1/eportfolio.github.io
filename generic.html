<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Anna Kakovka E-Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Anna Kakovka</strong> </a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>
<!-- Custom styles -->
<style>
/* Make all text white for dark theme */
body, p, ul, li, a, h1, h2, h3, h4, h5, h6, code, em, strong {
color: #ffffff !important;
}

/* Uniform section headings */
.major h3 {
font-size: 1.5rem;
font-weight: 600;
margin-bottom: 0.8em;
}

/* Bold subtitle style for Web Scraping, Summary, Reflection */
.subtitle {
font-size: 1.25rem;
font-weight: bold;
margin-top: 1.5em;
margin-bottom: 0.8em;
color: #ffffff !important;
}

.normal-text { font-weight: normal; }

ul.normal-text li { margin-bottom: 0.5em; }

a {
color: #ffffff !important;
text-decoration: underline;
}

code {
color: #ffefd6 !important;
background: rgba(255, 255, 255, 0.1);
padding: 2px 4px;
border-radius: 3px;
}

pre code {
display: block;
overflow-x: auto;
white-space: pre;
background: rgba(255, 255, 255, 0.08);
padding: 1rem;
border-radius: 6px;
}

em {
font-style: italic;
color: #e8e8e8 !important;
}

/* Reference styling — smaller spacing between lines */
.references p {
margin-bottom: 0.3em;
line-height: 1.2;
}

h4.section-label {
margin-top: 2em;
margin-bottom: 0.8em;
font-size: 1.2rem;
font-weight: 500;
color: #ffffff !important;
text-decoration: underline;
}
</style>
</head>

<body class="is-preload">


<!-- Menu -->
<nav id="menu">
<ul class="links">
<li><a href="index.html">Home</a></li>

<li><a href="landing.html">Personal Statement</a></li>

<li><a href="generic.html">Deciphering Big Data</a></li>

<li><a href="elements.html">Machine Learning</a></li>

<li><a href="elements1.html">Research Methods and Professional Practice</a></li>



</nav>


<!-- Main -->
<div id="main" class="alt">

<!-- Introduction -->
<section id="intro">
<div class="inner">
<header class="major">
<h1>Deciphering Big Data</h1>
</header>
<p>In a world overflowing with information, Big Data holds the key to understanding patterns that drive innovation, decision-making, and growth. The true challenge lies not in collecting data, but in deciphering it — transforming vast, unstructured information into meaningful insights. My journey in exploring Big Data focuses on bridging the gap between complexity and clarity, leveraging analytics, visualisation, and critical thinking to reveal stories hidden within the numbers.</p>
</div>
</section>

<!-- Learning Outcomes -->
<section id="learning-outcomes">
<div class="inner">
<header class="major">
<h3>Learning Outcomes</h3>
</header>
<p>I will learn:</p>
<ul>
<li>Show a comprehensive understanding of the core principles and signature features of Big Data as they manifest in Data Science.</li>
<li>Use a combination of data collection, cleaning, and preprocessing methods to transform messy datasets into a truly usable format.</li>
<li>Deploy analytical and machine-learning approaches like a comb across the data, lifting out the faint, almost hidden patterns and the gems of insight they hold.</li>
<li>Create data visualisations that clearly present complex findings with precision.</li>
<li>Evaluate issues surrounding data ethics, privacy considerations and governance structures that pop up across the sprawling landscape of big-data environments.</li>
<li>Interlace findings with data-driven solutions, giving decision-makers a solid foundation for informed choices across a kaleidoscope of contexts.</li>
</ul>
</div>
</section>

<!-- Discussion -->
<section id="discussion">
<div class="inner">
<header class="major">
<h3>Discussion</h3>
</header>
<p>Despite these benefits, Huxley et al. (2020) remind us that large-scale data collection comes with serious challenges. IoT devices generate massive amounts of data in different formats, which often makes it hard to clean, integrate and interpret effectively (Mansouri et al., 2021). Security and privacy risks are also significant — billions of connected devices increase the chances of data breaches and misuse of personal information (Tawalbeh et al., 2020). To manage these risks, frameworks such as the NIST IoT Security Baseline (Fagan et al., 2020) and the UK ICO’s IoT guidance (ICO, 2025) stress the importance of encryption, privacy-by-design, and limiting unnecessary data collection.</p>

<p>Overall, while IoT offers great opportunities for innovation and smarter systems, it must be developed responsibly. Balancing the benefits of data-driven insights with strong governance and ethical oversight is key to making IoT a trustworthy and sustainable technology.</p>

<h4 class="section-label">References</h4>
<div class="references">
<p><em>Fagan, M. et al.</em> (2020) <em>NISTIR 8259A: IoT Device Cybersecurity Capability Core Baseline.</em> Gaithersburg, MD: NIST.</p>
<p><em>Huxley, et al.</em> (2020).</p>
<p><em>ICO</em> (2025) <em>Guidance for consumer Internet of Things products and services.</em> Information Commissioner’s Office.</p>
<p><em>Mansouri, T., Farid, F. and Mammadli, A.</em> (2021) ‘IoT Data Quality Issues and Potential Solutions’, <em>arXiv preprint</em>, arXiv:2103.13303.</p>
<p><em>Nasajpour, M. et al.</em> (2020) ‘Internet of Things for Current COVID-19 and Future Pandemics’, <em>IEEE Access</em>, 8, pp. 188802–188826.</p>
<p><em>Nižetić, S. et al.</em> (2020) ‘Internet of Things (IoT): Opportunities, issues and challenges’, <em>Journal of Cleaner Production</em>, 274, 122877.</p>
<p><em>Tawalbeh, L. et al.</em> (2020) ‘IoT Privacy and Security: Challenges and Solutions’, <em>Applied Sciences</em>, 10(12), 4102.</p>
</div>
</div>
</section>


	<!-- Discussion 2 -->
<section id="Collaborative Discussion 2 - Comparing Compliance Laws">
<div class="inner">
<header class="major">
<h3>Collaborative Discussion 2 - Comparing Compliance Laws</h3>
</header>

<p>The General Data Protection Regulation (GDPR) establishes a strong framework for securing personal data, enshrined in Article 5(1)(f), which states that “personal data shall be processed in a manner that ensures appropriate security of the personal data” (ICO, n.d.). This is further detailed in Article 32, which requires controllers and processors to implement “appropriate technical and organisational measures” to ensure a level of security suitable to the risks involved (GDPR-info.eu, 2024). These measures include pseudonymisation, encryption, ensuring ongoing confidentiality, integrity, and availability of systems, and maintaining the ability to restore data in case of an incident. Importantly, the GDPR adopts a risk-based approach, where the level of protection must correspond to the sensitivity and volume of personal data being processed. </p>
<p>In the United Kingdom, the Information Commissioner’s Office (ICO) enforces similar requirements through the UK GDPR and the Data Protection Act 2018 (DPA 2018). The ICO refers to this as the “security principle,” requiring organisations to protect personal data against unauthorised or unlawful processing, accidental loss, or damage (ICO, n.d.). Although the UK GDPR largely mirrors the EU GDPR, the DPA 2018 introduces certain exemptions — for example, processing for national security, law enforcement, or domestic purposes may be exempt from some provisions (ICO, 2024). The ICO emphasises that what constitutes “appropriate” measures depends on factors such as the nature, scope, and context of processing, as well as the potential harm to individuals (ICO, 2024). </p>
<p>Both regimes expect organisations to employ technical and organisational controls such as access management, staff training, encryption, and robust incident response. These measures ensure data integrity and confidentiality while allowing accountability through regular audits and risk assessments (Burton, 2020). However, neither system mandates specific technologies — instead, they require proportionality. This flexibility ensures that security remains adaptable to evolving threats but can also lead to inconsistent interpretations of adequacy among organisations (Voigt and Von dem Bussche, 2017). </p>
<p>From a data-wrangling perspective, the security principle directly influences how organisations collect, process, and store personal data. Practitioners must ensure that datasets are minimised, anonymised where possible, and protected through encryption and restricted access. Regular monitoring and evaluation of data-handling processes are essential to maintain compliance. Furthermore, under the accountability principle, organisations must document their security decisions and be able to demonstrate compliance during ICO audits or investigations (European Commission, 2023). </p>
<p>In summary, both the EU GDPR and UK GDPR establish robust and flexible standards for securing personal data. While the DPA 2018 introduces limited exemptions, the core principle of proportional, risk-based security remains central. These frameworks underscore that protecting personal data is not merely a technical requirement but a fundamental obligation ensuring public trust in digital and data-driven systems. </p>


<h4 class="section-label">References</h4>
<div class="references">
<p><em>Burton, S.</em> (2020) <em>Data Protection Compliance in the UK: Challenges of Implementing GDPR.</em> Oxford: Oxford University Press.</p>
<p><em>European Commission</em> (2023) <em>EU GDPR: Security of Processing (Article 32).</em> Available at: https://gdpr-info.eu/art-32-gdpr/ (Accessed: 20 October 2025).</p>
<p><em>GDPR-info.eu</em> (2024) <em>Article 32 GDPR – Security of Processing.</em> Available at: https://gdpr-info.eu/art-32-gdpr/ (Accessed: 20 October 2025).</p>
<p><em>ICO</em> (n.d.) <em>Security – Integrity and Confidentiality (the Security Principle).</em> Information Commissioner’s Office. Available at: https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/security/a-guide-to-data-security/ (Accessed: 20 October 2025).</p>
<p><em>ICO</em> (2024) <em>Guide to the Data Protection Principles: Integrity and Confidentiality.</em> Information Commissioner’s Office. Available at: https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/data-protection-principles/ (Accessed: 20 October 2025).</p>
<p><em>Voigt, P. and Von dem Bussche, A.</em> (2017) <em>The EU General Data Protection Regulation (GDPR): A Practical Guide.</em> Cham: Springer International Publishing.</p>
</div>
</div>
</section>


<!-- Activities -->
<section id="activities">
<div class="inner">
<header class="major">
<h3>Activities</h3>
</header>

	
<p class="subtitle">Web Scraping “Data Scientist” Jobs with Python</p>

<p>This Python script demonstrates how to use <strong>Requests</strong> and <strong>BeautifulSoup4</strong> to scrape job postings containing the keyword “Data Scientist”. It fetches data from a tutorial-safe website (<a href="https://realpython.github.io/fake-jobs/" target="_blank" rel="noopener">Fake Jobs Demo Page</a>) and saves it as a <strong>JSON</strong> file.</p>

<pre><code class="language-python">
# scrape_data_scientist_jobs.py
"""
Scrape job postings containing 'Data Scientist' and save them to a JSON file.
Uses Requests for HTTP and BeautifulSoup for parsing HTML.
"""

import requests
from bs4 import BeautifulSoup
import json
import time

# 1. Identify the webpage (safe demo site)
URL = "https://realpython.github.io/fake-jobs/"
KEYWORD = "Data Scientist"

# 2. Send HTTP request
response = requests.get(URL)
response.raise_for_status() # ensure successful request

# 3. Parse HTML with BeautifulSoup
soup = BeautifulSoup(response.text, "html.parser")

# 4. Extract relevant data
jobs = []
for job_card in soup.find_all("div", class_="card-content"):
title = job_card.find("h2", class_="title").get_text(strip=True)
if KEYWORD.lower() in title.lower():
company = job_card.find("h3", class_="company").get_text(strip=True)
location = job_card.find("p", class_="location").get_text(strip=True)
link = job_card.find_next("a", string="Apply")["href"]
jobs.append({
"title": title,
"company": company,
"location": location,
"apply_url": link,
"keyword": KEYWORD,
"scraped_at": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
})

# 5. Store data in JSON format
output_file = "data_scientist_jobs.json"
with open(output_file, "w", encoding="utf-8") as f:
json.dump(jobs, f, indent=2, ensure_ascii=False)

print(f"✅ Scraped {len(jobs)} '{KEYWORD}' job(s). Data saved to {output_file}.")
</code></pre>

<p><em>Note:</em> This example uses a public tutorial site. Always check a site’s <code>robots.txt</code> file and terms of service before scraping.</p>

<p class="subtitle">Summary of findings</p>
<ul class="normal-text">
<li>I used <code>requests</code> to fetch an HTML page and <code>BeautifulSoup</code> to parse job listings containing the keyword “Data Scientist”.</li>
<li>The extracted data — including title, company, location, and apply link — were saved as a <code>JSON</code> file.</li>
<li>The process followed the Request → Protocol → Response pattern of inter-process communication.</li>
</ul>

<p class="subtitle">Critical reflection</p>
<p class="normal-text"><li>The main challenge was ensuring reliability and respecting ethical scraping rules.</li> 
<li>I used a static demo site (safe to scrape) to avoid legal or security issues.</li> 
<li>Data wrangling challenges include cleaning inconsistent data, changing page structures, and network errors.</li> 
<li>Using structured formats like JSON facilitates interoperability and data sharing.</li>
<li>In a team context, proper task separation (developer, tester, analyst) and documentation are essential for maintainability and reproducibility.</li></p>

<!-- NEW SUBSECTION ADDED: Security Requirements + Snippets -->
<p class="subtitle">Security Requirements Specification – Data Sharing API</p>

<p class="normal-text">
This short specification defines how a Python-based API securely exchanges data using JSON, XML, and SQL. All communication must use HTTPS with modern TLS to protect data in transit. Authentication relies on OAuth 2.1 or signed JWTs, and access is restricted by least-privilege roles at both the API and database layers. Secrets such as API keys and database credentials must be kept in a secret manager and never hardcoded. Inputs are limited to JSON and XML and must be validated against strict schemas. XML parsing disables DTDs and external entities to mitigate XXE. SQL access uses parameterised queries or a safe ORM to prevent injection. Logs capture security-relevant events while redacting personal data and credentials, and rate limiting is applied to defend against abuse and denial-of-service. Data is encrypted at rest, and retention/deletion policies are enforced to meet privacy and governance obligations. The CI/CD pipeline includes static analysis, dependency checks, and targeted security tests (SQLi, XXE, malformed input) before release. The whole team—developers, data engineers, and DevOps—shares responsibility for implementing and monitoring these controls.
</p>

<h4 class="section-label">Example secure practices (Python)</h4>

<pre><code class="language-python">
# secure_sql_insert.py
"""
Use parameterized queries to prevent SQL injection.
"""

import psycopg

with psycopg.connect("dbname=mydb user=api_user password=secret") as conn:
    with conn.cursor() as cur:
        cur.execute(
            "INSERT INTO users (id, name) VALUES (%s, %s)",
            (user_id, user_name)
        )
</code></pre>

<pre><code class="language-python">
# validate_json_input.py
"""
Validate incoming JSON data with a strict schema.
"""

import json
from jsonschema import validate, Draft202012Validator

schema = {
    "type": "object",
    "additionalProperties": False,
    "properties": {
        "id": {"type": "string"},
        "email": {"type": "string", "format": "email"}
    },
    "required": ["id", "email"]
}

payload = json.loads(request_body)  # never use pickle/yaml unsafe loaders
Draft202012Validator(schema).validate(payload)
</code></pre>

<pre><code class="language-python">
# safe_xml_parser.py
"""
Parse XML safely by disabling external entities (XXE protection) and network access.
"""

from lxml import etree

parser = etree.XMLParser(
    resolve_entities=False,
    no_network=True,
    dtd_validation=False,
    load_dtd=False
)
root = etree.fromstring(xml_data, parser=parser)
</code></pre>
<p>In summary, this API must ensure encrypted communication, authenticated access, safe input handling, and ongoing monitoring. By validating all inputs, securing data storage, and enforcing strict access control, the system will minimize risks associated with data sharing, scraping, and integration between Python applications and external systems.</p>
</div>
</section>

<!-- Reflections -->
<section id="Data Management Pipeline Test">
<div class="inner">
<header class="major">
<h3>Test</h3>
</header>

<!-- Data Management Pipeline Test — Reflection & Evidence -->
<h4>Data Management Pipeline Test — Reflection & Evidence</h4>

<div class="row gtr-200">
<!-- Left column: summary & skills -->
<div class="col-6 col-12-medium">
<h5>Result summary</h5>
<ul>
<li><strong>State:</strong> Finished</li>
<li><strong>Time taken:</strong> 24 mins 17 secs</li>
<li><strong>Marks:</strong> 2.00 / 2.00</li>
<li><strong>Grade:</strong> 10.00 / 10.00 (100%)</li>
<li><strong>Date:</strong> Sunday, 19 Oct 2025</li>
<li><strong>Course:</strong> DBD_PCOM7E (July 2025)</li>
</ul>

<h5>What I demonstrated</h5>
<ul>
<li>Matched Python concepts to their purposes (<code>in</code>/<code>not in</code>, <code>dict.values()</code>, string formatting, CSV writer, <code>strftime/strptime</code>, list comprehensions).</li>
<li>Matched Python practices to descriptions (PEP-8 naming & imports, repository organization, unit testing, “fast but clear,” version control, documentation, “use libraries”).</li>
<li>Achieved a <strong>100%</strong> overall grade across both questions.</li>
</ul>

<h5>Skills tagged</h5>
<p>Python fundamentals • Code quality (PEP-8) • Data handling (CSV, datetime) •
Software engineering practices • Version control (Git) • Documentation & testing • Problem solving</p>

<ul class="actions">
<li>
<a href="eportfolio_data_management_pipeline_test.html"

class="button" target="_blank" rel="noopener">
View full results
</a>
</li>
</ul>
</div>

<!-- Right column: reflection -->
<div class="col-6 col-12-medium">
<h5>Test</h5>
<p><strong>What went well:</strong> I quickly recognised standard Python concepts and practices and applied them accurately.
Concrete examples (e.g., <code>strftime/strptime</code> for dates, CSV writer for persistence, list comprehensions for fast data shaping) made each match unambiguous.</p>
<p><strong>What I reinforced:</strong> Clarity over cleverness (“fast but clear”); imports should be minimal and explicit; organizing a repository (plus READMEs) is as important as writing code.
Clear naming and targeted exceptions/documentation reduce debugging time.</p>
<p><strong>Next steps:</strong> Strengthen testing discipline by adding unit tests to upcoming mini-projects, practice more with the <code>datetime</code> formatting table, and continue using/contributing to high-quality libraries instead of rewriting solutions.</p>
</div>

</section>


<!-- Meeting Notes – Database Design Proposal: Deciphering Big Data -->
<section id="Meeting Notes – Database Design Proposal: Deciphering Big Data">
<div class="inner">
<header class="major">
<h3>Meeting Notes – Database Design Proposal: Deciphering Big Data</h3>
</header>


<b>Date:</b> 6th of September, 2025 <br>
<b>Attendees:</b> Kalifa, Daniella and Anna <br>
<b>Prepared by:</b> Anna

<hr>

<b>1. Project Overview</b>

The client operates in <b>Private Healthcare Services (UK)</b>, offering GP consultations, specialist clinics, diagnostic tests, and billing management.

<b>Objective (Updated by AK):</b> Build a secure, logical database for managing patient records, appointments, treatments, and billing while ensuring GDPR and NHS compliance.

<hr>

<b>2. Key Additions / Changes ( AK’s Edits)</b>

- Expanded <b>Objectives</b> section to emphasize <b>security, compliance, and scalability</b>.<br>
- Clarified <b>data entities</b> (Patient, Healthcare Professionals, Appointment, Treatment, Billing, Department, Insurance Provider).<br>
- Added details on <b>data types/formats</b> for standardization.<br>
- Updated attributes to include:<br>
&nbsp;&nbsp;&nbsp;&nbsp;• EmergencyContactName and Phone<br>
&nbsp;&nbsp;&nbsp;&nbsp;• NHSNumber<br>
- Enhanced clarity on <b>foreign key relationships</b>.<br>
- <b>Proposed addition:</b> Include an <b>ER diagram</b> and <b>sample SQL queries</b> for demonstration.<br>
- Defined <b>role-based access</b> for data security.<br>
- Expanded <b>data management pipeline</b> with a detailed cleansing workflow.<br>
- <b>Suggested section:</b> Add a <b>Summary/Evaluation</b> to discuss challenges, limitations, and improvements for future phases.

<hr>

<b>3. Technical Selections</b>

- <b>DBMS:</b> MySQL chosen for cost-effectiveness, scalability, and ACID compliance.<br>
- <b>Security:</b> Role-based access + encryption for sensitive data (e.g., NHS number, contact details).<br>
- <b>Operations:</b> CRUD-based management and reporting queries (e.g., patient history, departmental workload).

<hr>

<b>4. Next Steps</b>

- Add <b>ER diagram</b> and <b>sample SQL queries</b> (AK’s note).<br>
- Develop <b>Summary/Evaluation</b> section.<br>
- Review <b>data validation rules</b> for accuracy and compliance.<br>
- Schedule a <b>follow-up review with the client</b> for design confirmation.
</section>

<!--Part 2 – Reflection Section (≈1,000 words) -->
<section id="Part 2 – Reflection(≈1,000 words)">
<div class="inner">
<header class="major">
<h3>Part 2 – Reflection (≈1,000 words)</h3>
</header>

<b>Introduction</b>
<p>This reflection employs Rolfe et al.’s (2001) model What? So what? Now what? to analyse learning and development during the MedicaidUK database project. It focuses on technical competence, teamwork, and professional growth achieved through engagement with the data-wrangling module.</p>

<b>What?</b>

<p>The project objective was to design a secure and scalable database for MedicaidUK. My individual responsibilities included logical schema creation, validation of entity relationships, and documentation of compliance mechanisms. I contributed to the initial design proposal, developed entity attributes, and assisted in implementing schema components within MySQL.</p>
<p>Engagement in data-wrangling activities involved extracting datasets from simulated sources, cleaning inconsistent records, and testing validation rules. I applied techniques such as deduplication, type standardisation, and referential checks to ensure data reliability.</p>
<p>The collaborative aspect was equally significant. Regular virtual meetings allowed for reviewing schema consistency and resolving design conflicts. These sessions required concise technical communication and collective decision-making to achieve consensus on entity structures and naming conventions.</p>

<b>So What?</b>
<p>Working on this project clarified how abstract data-modelling theory operates within practical system design. Converting conceptual models into executable SQL schemas exposed challenges in maintaining referential integrity, enforcing constraints, and balancing normalisation with query efficiency. The iterative process revealed that even minor design inconsistencies can have cascading effects on functionality and reporting accuracy.</p>
<p>A deeper understanding of ethical and legal dimensions of data management also emerged. Implementing access-control layers and encryption concepts provided insight into how technical design upholds confidentiality and trust. Marquis (2024) emphasised the preventive function of role-based access control, a principle integrated into the final schema.</p>
<p>On a personal level, initial frustration over syntax errors and design revisions gradually transformed into appreciation for precision and structured problem-solving. The experience emphasised perseverance and collaboration as essential professional attributes. Feedback from peers and tutors promoted reflective practice and critical thinking, shifting focus from merely completing tasks to evaluating decisions in relation to best practice and research evidence.</p>
<p>The emotional and cognitive engagement throughout the project strengthened confidence in handling complexity and communicating rationale to non-technical audiences. It highlighted that effective database design is not solely a technical exercise but also a process of reasoning, negotiation, and accountability.</p>

<b>Now What?</b>
<p>The knowledge gained from this project provides a foundation for future professional advancement. Continued development will focus on extending expertise in cloud-based database management, data-pipeline automation, and advanced analytics. The integration of predictive modelling and machine-learning techniques, as discussed by Na et al. (2023), represents a logical progression for applying these competencies to enhance healthcare operations.</p>
<p>Further training in cybersecurity and data-protection frameworks will strengthen capacity to design and audit compliant systems. Participation in industry certifications related to data governance or privacy will consolidate the theoretical and practical learning achieved in this module.</p>
<p>From a collaborative perspective, I will apply lessons learned about team coordination and communication in future projects. Establishing clearer task allocation, documentation standards, and version control will improve efficiency and reduce conflict in distributed teams.</p>
<b>Summary</b>
<p>In summary, this reflective process has affirmed the importance of ongoing learning and ethical responsibility in data-focused professions. The MedicaidUK project turned theoretical knowledge into practical skill, aligning technical expertise with professional integrity and flexibility. The insights gained will inform future contributions to data management projects that require analytical accuracy, compliance awareness, and interdisciplinary teamwork.
</p>

<h4 class="section-label">References</h4>
<div class="references">
<p><em>Batko, K.</em> and <em>Ślęzak, A.</em> (2022) ‘The use of big data analytics in healthcare.’ <em>Journal of Big Data</em>, 9(3), pp. 1–24.</p>

<p><em>Bitrián, P.</em>, <em>Buil, I.</em>, <em>Catalán, S.</em> and <em>Merli, D.</em> (2024) ‘Gamification in workforce training: Improving employees’ self-efficacy and information security and data protection behaviours.’ <em>Journal of Business Research</em>, 179, p. 114685.</p>

<p><em>Marquis, Y. A.</em> (2024) ‘From theory to practice: Implementing effective role-based access control strategies to mitigate insider risks in diverse organisational contexts.’ <em>Journal of Engineering Research and Reports</em>, 26(5), pp. 138–154.</p>

<p><em>Na, L.</em> et al. (2023) ‘Patient outcome predictions improve operations at a large hospital network.’ <em>arXiv.org.</em> Available at: 
<a href="https://arxiv.org/abs/2305.15629" target="_blank">https://arxiv.org/abs/2305.15629</a>.

</p>

<p><em>Oracle</em> (2025) <em>MySQL Workbench [Computer Program].</em> Available at: 
<a href="https://www.mysql.com/products/workbench/" target="_blank">https://www.mysql.com/products/workbench/</a> 
(Accessed: 6 Sept 2025).
</p>

<p><em>Rolfe, G.</em>, <em>Freshwater, D.</em> and <em>Jasper, M.</em> (2001) <em>Critical reflection in nursing and the helping professions: A user’s guide.</em> Basingstoke: Palgrave Macmillan.</p>

<p><em>Tariq, S.</em>, <em>Tariq, S.</em> and <em>Ahmad Adnan Shoukat</em> (2023) ‘Centralised healthcare database for ensuring better healthcare: Are we lagging behind?’ <em>Pakistan Journal of Medical Sciences</em>, 40(3).</p>
</div>


</section>

</div>

<!-- Footer -->
<footer id="footer">
<div class="inner">
<ul class="icons">
<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>

<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>

</ul>
<ul class="copyright">
<li>&copy; Untitled</li>
<li>Design: <a href="https://html5up.net">HTML5 UP</a></li>

</ul>
</div>
</footer>

</div>



<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>

<script src="assets/js/jquery.scrolly.min.js"></script>

<script src="assets/js/jquery.scrollex.min.js"></script>

<script src="assets/js/browser.min.js"></script>

<script src="assets/js/breakpoints.min.js"></script>

<script src="assets/js/util.js"></script>

<script src="assets/js/main.js"></script>


</body>
</html>

