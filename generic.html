<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Decipheting Big Data</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>

		<!-- Custom styles -->
		<style>
			/* Make all text white for dark theme */
			body, p, ul, li, a, h1, h2, h3, h4, h5, h6, code, em, strong {
				color: #ffffff !important;
			}

			/* Transparent name styling */
			.logo strong {
				color: rgba(255, 255, 255, 0.3) !important; /* semi-transparent white */
				transition: color 0.3s ease;
			}
			.logo strong:hover {
				color: rgba(255, 255, 255, 0.6) !important; /* slightly brighter on hover */
			}

			/* Uniform section headings */
			.major h3 {
				font-size: 1.5rem;
				font-weight: 600;
				margin-bottom: 0.8em;
			}

			/* Bold subtitle style for Web Scraping, Summary, Reflection */
			.subtitle {
				font-size: 1.25rem;
				font-weight: bold;
				margin-top: 1.5em;
				margin-bottom: 0.8em;
				color: #ffffff !important;
			}

			.normal-text { font-weight: normal; }

			ul.normal-text li { margin-bottom: 0.5em; }

			a {
				color: #ffffff !important;
				text-decoration: underline;
			}

			code {
				color: #ffefd6 !important;
				background: rgba(255, 255, 255, 0.1);
				padding: 2px 4px;
				border-radius: 3px;
			}

			pre code {
				display: block;
				overflow-x: auto;
				white-space: pre;
				background: rgba(255, 255, 255, 0.08);
				padding: 1rem;
				border-radius: 6px;
			}

			em {
				font-style: italic;
				color: #e8e8e8 !important;
			}

			/* Reference styling — smaller spacing between lines */
			.references p {
				margin-bottom: 0.3em;
				line-height: 1.2;
			}

			h4.section-label {
				margin-top: 2em;
				margin-bottom: 0.8em;
				font-size: 1.2rem;
				font-weight: 500;
				color: #ffffff !important;
				text-decoration: underline;
			}
		</style>
	</head>

	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Anna Kakovka</strong> </a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

			<!-- Menu -->
			<nav id="menu">
				<ul class="links">
					<li><a href="index.html">Home</a></li>
					<li><a href="landing.html">Personal Statement</a></li>
					<li><a href="generic.html">Deciphering Big Data</a></li>
					<li><a href="elements.html">Machine Learning</a></li>
					<li><a href="elements1.html">Research Methods and Professional Practice</a></li>
				</ul>
			</nav>

			<!-- Main -->
			<div id="main" class="alt">

				<!-- Introduction -->
				<section id="intro">
					<div class="inner">
						<header class="major">
							<h1>Deciphering Big Data</h1>
						</header>
						<p>In a world overflowing with information, Big Data holds the key to understanding patterns that drive innovation, decision-making, and growth. The true challenge lies not in collecting data, but in deciphering it — transforming vast, unstructured information into meaningful insights. My journey in exploring Big Data focuses on bridging the gap between complexity and clarity, leveraging analytics, visualisation, and critical thinking to reveal stories hidden within the numbers.</p>
					</div>
				</section>

				<!-- Learning Outcomes -->
				<section id="learning-outcomes">
					<div class="inner">
						<header class="major">
							<h3>Learning Outcomes</h3>
						</header>
						<p>I will learn:</p>
						<ul>
							<li>Show a comprehensive understanding of the core principles and signature features of Big Data as they manifest in Data Science.</li>
							<li>Use a combination of data collection, cleaning, and preprocessing methods to transform messy datasets into a truly usable format.</li>
							<li>Deploy analytical and machine-learning approaches like a comb across the data, lifting out the faint, almost hidden patterns and the gems of insight they hold.</li>
							<li>Create data visualisations that clearly present complex findings with precision.</li>
							<li>Evaluate issues surrounding data ethics, privacy considerations and governance structures that pop up across the sprawling landscape of big-data environments.</li>
							<li>Interlace findings with data-driven solutions, giving decision-makers a solid foundation for informed choices across a kaleidoscope of contexts.</li>
						</ul>
					</div>
				</section>

				<!-- Discussion -->
				<section id="discussion">
					<div class="inner">
						<header class="major">
							<h3>Discussion</h3>
						</header>
						<p>Despite these benefits, Huxley et al. (2020) remind us that large-scale data collection comes with serious challenges. IoT devices generate massive amounts of data in different formats, which often makes it hard to clean, integrate and interpret effectively (Mansouri et al., 2021). Security and privacy risks are also significant — billions of connected devices increase the chances of data breaches and misuse of personal information (Tawalbeh et al., 2020). To manage these risks, frameworks such as the NIST IoT Security Baseline (Fagan et al., 2020) and the UK ICO’s IoT guidance (ICO, 2025) stress the importance of encryption, privacy-by-design, and limiting unnecessary data collection.</p>

						<p>Overall, while IoT offers great opportunities for innovation and smarter systems, it must be developed responsibly. Balancing the benefits of data-driven insights with strong governance and ethical oversight is key to making IoT a trustworthy and sustainable technology.</p>

						<h4 class="section-label">References</h4>
						<div class="references">
							<p><em>Fagan, M. et al.</em> (2020) <em>NISTIR 8259A: IoT Device Cybersecurity Capability Core Baseline.</em> Gaithersburg, MD: NIST.</p>
							<p><em>Huxley, [Initials]. et al.</em> (2020) [Title of article]. <em>[Journal/Publisher]</em>.</p>
							<p><em>ICO</em> (2025) <em>Guidance for consumer Internet of Things products and services.</em> Information Commissioner’s Office.</p>
							<p><em>Mansouri, T., Farid, F. and Mammadli, A.</em> (2021) ‘IoT Data Quality Issues and Potential Solutions’, <em>arXiv preprint</em>, arXiv:2103.13303.</p>
							<p><em>Nasajpour, M. et al.</em> (2020) ‘Internet of Things for Current COVID-19 and Future Pandemics’, <em>IEEE Access</em>, 8, pp. 188802–188826.</p>
							<p><em>Nižetić, S. et al.</em> (2020) ‘Internet of Things (IoT): Opportunities, issues and challenges’, <em>Journal of Cleaner Production</em>, 274, 122877.</p>
							<p><em>Tawalbeh, L. et al.</em> (2020) ‘IoT Privacy and Security: Challenges and Solutions’, <em>Applied Sciences</em>, 10(12), 4102.</p>
						</div>
					</div>
				</section>

				<!-- Activities -->
				<section id="activities">
					<div class="inner">
						<header class="major">
							<h3>Activities</h3>
						</header>

						<p class="subtitle">Web Scraping “Data Scientist” Jobs with Python</p>

						<p>This Python script demonstrates how to use <strong>Requests</strong> and <strong>BeautifulSoup4</strong> to scrape job postings containing the keyword “Data Scientist”. It fetches data from a tutorial-safe website (<a href="https://realpython.github.io/fake-jobs/" target="_blank" rel="noopener">Fake Jobs Demo Page</a>) and saves it as a <strong>JSON</strong> file.</p>

<pre><code class="language-python">
# scrape_data_scientist_jobs.py
"""
Scrape job postings containing 'Data Scientist' and save them to a JSON file.
Uses Requests for HTTP and BeautifulSoup for parsing HTML.
"""

import requests
from bs4 import BeautifulSoup
import json
import time

# 1. Identify the webpage (safe demo site)
URL = "https://realpython.github.io/fake-jobs/"
KEYWORD = "Data Scientist"

# 2. Send HTTP request
response = requests.get(URL)
response.raise_for_status()  # ensure successful request

# 3. Parse HTML with BeautifulSoup
soup = BeautifulSoup(response.text, "html.parser")

# 4. Extract relevant data
jobs = []
for job_card in soup.find_all("div", class_="card-content"):
    title = job_card.find("h2", class_="title").get_text(strip=True)
    if KEYWORD.lower() in title.lower():
        company = job_card.find("h3", class_="company").get_text(strip=True)
        location = job_card.find("p", class_="location").get_text(strip=True)
        link = job_card.find_next("a", string="Apply")["href"]
        jobs.append({
            "title": title,
            "company": company,
            "location": location,
            "apply_url": link,
            "keyword": KEYWORD,
            "scraped_at": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime())
        })

# 5. Store data in JSON format
output_file = "data_scientist_jobs.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(jobs, f, indent=2, ensure_ascii=False)

print(f"✅ Scraped {len(jobs)} '{KEYWORD}' job(s). Data saved to {output_file}.")
</code></pre>

						<p><em>Note:</em> This example uses a public tutorial site. Always check a site’s <code>robots.txt</code> file and terms of service before scraping.</p>

						<p class="subtitle">Summary of findings</p>
						<ul class="normal-text">
							<li>I used <code>requests</code> to fetch an HTML page and <code>BeautifulSoup</code> to parse job listings containing the keyword “Data Scientist”.</li>
							<li>The extracted data — including title, company, location, and apply link — were saved as a <code>JSON</code> file.</li>
							<li>The process followed the Request → Protocol → Response pattern of inter-process communication.</li>
						</ul>

						<p class="subtitle">Critical reflection</p>
						<p class="normal-text"><li>The main challenge was ensuring reliability and respecting ethical scraping rules.</li> 
							<li>I used a static demo site (safe to scrape) to avoid legal or security issues.</li> 
							<li>Data wrangling challenges include cleaning inconsistent data, changing page structures, and network errors.</li> 
							<li>Using structured formats like JSON facilitates interoperability and data sharing.</li>
							<li>In a team context, proper task separation (developer, tester, analyst) and documentation are essential for maintainability and reproducibility.</li></p>

						
					</div>
				</section>

		<!-- Reflections -->
<section id="Data Management Pipeline Test">
  <div class="inner">
    <header class="major">
      <h3>Test</h3>
    </header>

    <!-- Data Management Pipeline Test — Reflection & Evidence -->
    <h4>Data Management Pipeline Test — Reflection & Evidence</h4>

    <div class="row gtr-200">
      <!-- Left column: summary & skills -->
      <div class="col-6 col-12-medium">
        <h5>Result summary</h5>
        <ul>
          <li><strong>State:</strong> Finished</li>
          <li><strong>Time taken:</strong> 24 mins 17 secs</li>
          <li><strong>Marks:</strong> 2.00 / 2.00</li>
          <li><strong>Grade:</strong> 10.00 / 10.00 (100%)</li>
          <li><strong>Date:</strong> Sunday, 19 Oct 2025</li>
          <li><strong>Course:</strong> DBD_PCOM7E (July 2025)</li>
        </ul>

        <h5>What I demonstrated</h5>
        <ul>
          <li>Matched Python concepts to their purposes (<code>in</code>/<code>not in</code>, <code>dict.values()</code>, string formatting, CSV writer, <code>strftime/strptime</code>, list comprehensions).</li>
          <li>Matched Python practices to descriptions (PEP-8 naming & imports, repository organization, unit testing, “fast but clear,” version control, documentation, “use libraries”).</li>
          <li>Achieved a <strong>100%</strong> overall grade across both questions.</li>
        </ul>

        <h5>Skills tagged</h5>
        <p>Python fundamentals • Code quality (PEP-8) • Data handling (CSV, datetime) •
           Software engineering practices • Version control (Git) • Documentation & testing • Problem solving</p>

        <ul class="actions">
          <li>
            <a href="eportfolio_data_management_pipeline_test.html"
               class="button" target="_blank" rel="noopener">
               View full results
            </a>
          </li>
        </ul>
      </div>

      <!-- Right column: reflection -->
      <div class="col-6 col-12-medium">
        <h5>Test</h5>
        <p><strong>What went well:</strong> I quickly recognized standard Python concepts and practices and applied them accurately.
           Concrete examples (e.g., <code>strftime/strptime</code> for dates, CSV writer for persistence, list comprehensions for fast data shaping) made each match unambiguous.</p>
        <p><strong>What I reinforced:</strong> Clarity over cleverness (“fast but clear”); imports should be minimal and explicit; organizing a repository (plus READMEs) is as important as writing code.
           Clear naming and targeted exceptions/documentation reduce debugging time.</p>
        <p><strong>Next steps:</strong> Strengthen testing discipline by adding unit tests to upcoming mini-projects, practice more with the <code>datetime</code> formatting table, and continue using/contributing to high-quality libraries instead of rewriting solutions.</p>
      </div>
  
</section>


	    <!-- Meeting Notes – Database Design Proposal: Deciphering Big Data -->
<section id="Meeting Notes – Database Design Proposal: Deciphering Big Data">
  <div class="inner">
    <header class="major">
      <h3>Meeting Notes – Database Design Proposal: Deciphering Big Data</h3>
    </header>


<b>Date:</b> 6th of September, 2025 <br>
<b>Attendees:</b> Kalifa, Daniella and Anna <br>
<b>Prepared by:</b> Anna

<hr>

<b>1. Project Overview</b>

The client operates in <b>Private Healthcare Services (UK)</b>, offering GP consultations, specialist clinics, diagnostic tests, and billing management.

<b>Objective (Updated by AK):</b> Build a secure, logical database for managing patient records, appointments, treatments, and billing while ensuring GDPR and NHS compliance.

<hr>

<b>2. Key Additions / Changes ( AK’s Edits)</b>

- Expanded <b>Objectives</b> section to emphasize <b>security, compliance, and scalability</b>.<br>
- Clarified <b>data entities</b> (Patient, Healthcare Professionals, Appointment, Treatment, Billing, Department, Insurance Provider).<br>
- Added details on <b>data types/formats</b> for standardization.<br>
- Updated attributes to include:<br>
  &nbsp;&nbsp;&nbsp;&nbsp;• EmergencyContactName and Phone<br>
  &nbsp;&nbsp;&nbsp;&nbsp;• NHSNumber<br>
- Enhanced clarity on <b>foreign key relationships</b>.<br>
- <b>Proposed addition:</b> Include an <b>ER diagram</b> and <b>sample SQL queries</b> for demonstration.<br>
- Defined <b>role-based access</b> for data security.<br>
- Expanded <b>data management pipeline</b> with a detailed cleansing workflow.<br>
- <b>Suggested section:</b> Add a <b>Summary/Evaluation</b> to discuss challenges, limitations, and improvements for future phases.

<hr>

<b>3. Technical Selections</b>

- <b>DBMS:</b> MySQL chosen for cost-effectiveness, scalability, and ACID compliance.<br>
- <b>Security:</b> Role-based access + encryption for sensitive data (e.g., NHS number, contact details).<br>
- <b>Operations:</b> CRUD-based management and reporting queries (e.g., patient history, departmental workload).

<hr>

<b>4. Next Steps</b>

- Add <b>ER diagram</b> and <b>sample SQL queries</b> (AK’s note).<br>
- Develop <b>Summary/Evaluation</b> section.<br>
- Review <b>data validation rules</b> for accuracy and compliance.<br>
- Schedule a <b>follow-up review with the client</b> for design confirmation.
	  </section>
	  
	  <!-- Reflection -->
				<section id="Refletion">
					<div class="inner">
						<header class="major">
							<h3>Eeflection</h3>
						</header>

						<p class="subtitle">Web Scraping “Data Scientist” Jobs with Python</p>


			</div>

			<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Untitled</li>
						<li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		</div>


						



		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

	</body>
</html>




















